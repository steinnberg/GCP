# ðŸ“Š Projet pÃ©dagogique â€“ Data dans le Cloud avec GCP + DBT

## ðŸŽ¯ Objectif du projet

Ce projet a pour objectif de construire un pipeline ELT complet dans le cloud Ã  lâ€™aide de :
- Google Cloud Platform (GCP)
- DBT Core (Data Build Tool)
- BigQuery + Cloud Storage
- Dataset Olist (e-commerce brÃ©silien)

## ðŸ§± Architecture


## ðŸ“ Dossiers

- `/data/` : fichiers CSV sources
- `/models/` : modÃ¨les SQL DBT (staging, silver, gold)
- `/scripts/` : scripts dâ€™automatisation
- `/dashboards/` : exports Looker Studio ou Streamlit
- `README.md` : ce fichier

## ðŸš€ Ã‰tapes principales

1. CrÃ©ation du projet GCP + bucket + import CSV
2. Connexion DBT Ã  BigQuery
3. ModÃ©lisation Bronze â†’ Silver â†’ Gold
4. CrÃ©ation de tests et documentation automatique
5. Dashboard avec KPIs dans Looker Studio

## ðŸ§ª Stack utilisÃ©e

- Google Cloud Platform (GCP)
- DBT Core (local)
- Python 3.10+
- BigQuery
- Looker Studio

## ðŸ“¦ Installation rapide

```bash
# CrÃ©er un environnement
python -m venv venv && source venv/bin/activate

# Installer les dÃ©pendances
pip install -r requirements.txt

```

## ðŸ“Š Dataset

Dataset Olist e-commerce :
https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce

## ðŸ™Œ Auteurs

Projet rÃ©alisÃ© dans le cadre de la formation Data dans le Cloud Ã  MyDigitalSchool.


---

### âœ… `requirements.txt` minimal pour DBT + GCP

```txt
dbt-core>=1.7
dbt-bigquery>=1.7
google-cloud-storage>=2.12.0
pandas>=2.2.2
notebook
```

---