# ğŸ“¦ Cas Pratique 2 â€“ API publique â JSON â CSV â BigQuery

## ğŸ¯ Objectif pÃ©dagogique

Apprendre Ã  :
- Interroger une API publique (REST)
- Extraire des donnÃ©es au format JSON
- Convertir et structurer les donnÃ©es avec `pandas` en CSV
- Uploader le fichier dans BigQuery via lâ€™interface GCP

---

## ğŸ§° PrÃ©requis

- Un projet GCP actif avec BigQuery activÃ©
- Un bucket Cloud Storage crÃ©Ã©
- Un environnement Python local ou Google Colab
- BibliothÃ¨ques Python : `requests`, `pandas`, `google-cloud-bigquery`

---

## ğŸ” API choisie : OpenFoodFacts

- Endpoint : `https://world.openfoodfacts.org/api/v0/product/[code].json`
- Documentation : [https://world.openfoodfacts.org/data](https://world.openfoodfacts.org/data)

Nous allons extraire des informations nutritionnelles pour une sÃ©lection de produits alimentaires.

---

## ğŸ§­ Ã‰tapes

### 1. ğŸ Script Python pour requÃªte API + conversion CSV
# 
# Exporter en CSV
- df = pd.DataFrame(produits)

- df.to_csv("openfoodfacts_sample.csv", index=False)

- print("âœ… CSV exportÃ© avec succÃ¨s !")

---
### 2. â˜ï¸ Uploader le CSV dans Cloud Storage

Vous pouvez rÃ©utiliser le bucket crÃ©Ã© dans le cas pratique Lab1.md :
```
gsutil cp openfoodfacts_sample.csv gs://data-cloud-kadri/
```

### 3. ğŸ§­ Importer le CSV dans BigQuery
- AccÃ©der Ã  BigQuery > Explorer
- SÃ©lectionner votre dataset (ou en crÃ©er un)
- Cliquez sur CrÃ©er une table
- Source : Cloud Storage ou fichier local
- Format : CSV
- DÃ©tection automatique des types (ou schema manuel si souhaitÃ©)
- Nom de table : openfood_products
- Valider lâ€™import

###  ğŸ“Œ RÃ©sultat attendu

Une table openfood_products dans BigQuery avec les colonnes :
- code
- product_name
- brands
- nutriscore_grade
- energy_100g
- fat_100g
- sugars_100g
- salt_100g

### ğŸ§ª Livrables

âœ… Fichier openfoodfacts_sample.csv
âœ… Capture dâ€™Ã©cran de la table dans BigQuery
âœ… Script Python extract_openfood_api.py dans un dossier scripts/
âœ… (optionnel) Lien du bucket contenant le fichier CSV
---

### Visualiser un fichier CSV depuis Cloud Storage dans BigQuery

1. VÃ©rifie que ton fichier est bien dans le bucket

Aller sur https://console.cloud.google.com/storage/browser
Clique sur ton bucket (ex. data-cloud-kadri)
Tu verras openfoodfacts_sample.csv (ou autre)

2. CrÃ©e un dataset dans BigQuery

Va sur https://console.cloud.google.com/bigquery
Dans le panneau de gauche, clique sur ton projet
Clique sur + CrÃ©er un dataset
Nom : api_data ou openfood
Emplacement : europe-west1

3. CrÃ©e une table depuis Cloud Storage

Toujours dans BigQuery, clique sur + CrÃ©er une table
Source : Google Cloud Storage
Dans le champ URI, mets le chemin du fichier, par exemple :
```
gs://data-cloud-kadri/openfoodfacts_sample.csv
```
- Format de fichier : CSV


Dataset de destination : ton dataset crÃ©Ã© (api_data)
Nom de la table : openfood_products
DÃ©tection automatique du schÃ©ma 
Clique sur CrÃ©er une table

### ğŸ‘ï¸ 4. Visualiser les donnÃ©es comme une table

Une fois la table importÃ©e :

Tu peux cliquer dessus dans BigQuery
Aller dans lâ€™onglet Â« DÃ©tails Â» et Â« AperÃ§u Â»
Ou Ã©crire une requÃªte SQL comme :
```
SELECT * FROM `data-cloud-kadri.api_data.openfood_products` LIMIT 10;
```

### ğŸ“Œ Astuce

Il est possible d'automatiser cette Ã©tape avec DBT ou Python plus tard.



### ğŸ’¬ Ã€ discuter

- Que se passe-t-il si le JSON est mal structurÃ© ou incomplet ?
- Pourquoi BigQuery est mieux quâ€™un fichier Excel ?
- Quels autres champs pertinents pour une analyse nutritionnelle (labels, ingrÃ©dients, scores) ?

### ğŸ“š Ressources utiles

- OpenFoodFacts API : https://world.openfoodfacts.org/data
- BigQuery : https://cloud.google.com/bigquery/docs/quickstarts
- Pandas : https://pandas.pydata.org